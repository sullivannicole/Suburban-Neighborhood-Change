---
title: "Longitudinal Clustering"
output: html_notebook
---
-----------------------------------

# Longitudinal Clustering for 2 timepoints, 2000 and 2017, on

-----------------------------------

## % POC
## % 65+
## % "New" Builds
## Median Household Income
## Median Estimated Market Value of Parcel
## Median Rent

```{r}
library(tidyverse)
library(kml3d) # for longitudinal clustering
library(stringr) # for num_extract algorithm
library(MASS) # for AIC
library(GGally) # for correlation matrix
library(extrafont) # for fonts for plots
library(pander) # to tidy model output
library(openxlsx)
```

```{r}
num_extract <- function(string){ 
  str_extract(string, "\\-*\\d+\\.*\\d*")
} 

# Import data
x00_17 <- read_csv("Data/2000 and 2017 Values for SNC Tracts and Variables.csv")
x00 <- read_csv("Data/cleaned_variables2000.csv")
x15 <- read_csv("Data/cleaned_variables2015.csv")

# Order the variables for ease and convert to class data.frame (algorithm will not recognize data_fr)
cl00_17 <- x00_17 %>%
  mutate(percentPOC2000 = percentPOC2000*100,
         perSixFive2000 = perSixFive2000*100,
         builtSince00_2000 = builtSince00_2000*100) %>%
  dplyr::select(TRACT, percentPOC2000, perc_poc, perSixFive2000, perc_65up, medHHinc2000, median_hhi, MedianValue2000, emv, rent2000, rent, builtSince00_2000, perc_new_bld) %>%
  as.data.frame()

cld_snc <- cld3d(cl00_17, timeInData = list(poc = 2:3, eld = 4:5, hhi = 6:7, emv = 8:9, rent = 10:11, blds = 12:13))

kml3d(cld_snc)
choice(cld_snc)

# Take a look at 3 clusters
cl00_17$clusters <- getClusters(cld_snc, 3)
```

Calinski-Harabasz criterion indicates between 2 and 3 clusters is a good choice.

Model on 3 clusters.  First, take a look at correlation matrices to remove correlated predictors.

```{r}
# Convert clusters to numeric dummy variables
cl_mod <- cl00_17 %>%
  mutate(clusters = ifelse(clusters == "A", 1,
                           ifelse(clusters == "B", 2, 3)))

# Correlation Matrices by cluster assignment
ggplot <- function(...)
ggplot2::ggplot(...) + scale_color_brewer(palette="Purples") + scale_fill_brewer(palette="Purples")
unlockBinding("ggplot",parent.env(asNamespace("GGally")))
assign("ggplot",ggplot,parent.env(asNamespace("GGally")))

graph_corr <- ggpairs(cl00_17, mapping = aes(color = clusters),
                      columns = c('percentPOC2000', 'perc_poc', 'perSixFive2000', 'perc_65up', 'medHHinc2000', 'median_hhi', 'MedianValue2000', 'emv', 'builtSince00_2000', 'perc_new_bld', "clusters"),
                      columnLabels = c('% POC 00', '% POC 17', '% 65+ 00', '% 65+ 17', 'HHI 00', 'HHI 17', 'EMV 00', 'EMV 17', 'New Builds 00', 'New Builds 17', "clusters"))

graph_corr <- graph_corr + theme(text = element_text(family = "Tw Cen MT"),
                                 strip.background = element_blank(),
                                 panel.background = element_rect(fill = "white"),
                                 panel.grid = element_line(color = "white"))

graph_corr

ggsave("Correlation Matrices by cluster assignment.png", width = 12, height = 8)


# Correlation Matrices without cluster assignment

# snc_corr <- cl00_17 %>% mutate(TRACT = as.character(TRACT))
# 
# corr_fn <- function(data, mapping, ...) {   
# 	ggplot(data = data, mapping = mapping) +     # make data points transparent     
# 	geom_point(alpha = .5, color = "lightsteelblue4", size = 0.6) +     # add default smoother     
# 	geom_smooth(se = FALSE, color = "#6666CC", size = 0.2) +
#   #scale_fill_brewer(palette="Purples") +
#   theme(text = element_text(size = 5, family = "Tw Cen MT"),
#           strip.background = element_rect(fill = "white"))
# }  
# 
# ggpairs(select_if(snc_corr, is.numeric),
#         lower = list(
#           continuous = corr_fn
#           ))

```

Clearly, 2000 and 2017 values are correlated.  Remove 2000 variables and look at correlation matrix.

```{r}
# Correlation Matrices by cluster assignment, no 2000 variables
ggplot <- function(...)
ggplot2::ggplot(...) + scale_color_brewer(palette="Purples") + scale_fill_brewer(palette="Purples")
unlockBinding("ggplot",parent.env(asNamespace("GGally")))
assign("ggplot",ggplot,parent.env(asNamespace("GGally")))

graph_corr <- ggpairs(cl00_17, mapping = aes(color = clusters),
                      columns = c('perc_poc', 'perc_65up', 'median_hhi', 'emv', 'perc_new_bld', "clusters"),
                      columnLabels = c('% POC 17', '% 65+ 17', 'HHI 17', 'EMV 17', 'New Builds 17', "clusters"))

graph_corr <- graph_corr + theme(text = element_text(family = "Tw Cen MT"),
                                 strip.background = element_blank(),
                                 panel.background = element_rect(fill = "white"),
                                 panel.grid = element_line(color = "white"))

graph_corr

#ggsave("Results/Longitudinal Clustering/Correlation Matrices by cluster assignment - 2017 only.png", width = 12, height = 8)


```

Still a strong correlation between median household income and median home value.  Drop median home value (this is a constructed, more subjective value) in favor of hhi.  Look at the matrices one last time.

```{r}
# Correlation Matrices by cluster assignment, no 2000 variables and no EMV
ggplot <- function(...)
ggplot2::ggplot(...) + scale_color_brewer(palette="Purples") + scale_fill_brewer(palette="Purples")
unlockBinding("ggplot",parent.env(asNamespace("GGally")))
assign("ggplot",ggplot,parent.env(asNamespace("GGally")))

graph_corr <- ggpairs(cl00_17, mapping = aes(color = clusters),
                      columns = c('perc_poc', 'perc_65up', 'median_hhi', 'perc_new_bld', "clusters"),
                      columnLabels = c('% POC 17', '% 65+ 17', 'HHI 17', 'New Builds 17', "clusters"))

graph_corr <- graph_corr + theme(text = element_text(family = "Tw Cen MT"),
                                 strip.background = element_blank(),
                                 panel.background = element_rect(fill = "white"),
                                 panel.grid = element_line(color = "white"))

graph_corr

#ggsave("Results/Longitudinal Clustering/Correlation Matrices by cluster assignment - 2017 sans EMV.png", width = 12, height = 8)


```

```{r}
# Model remaining variables on clusters to see if there are any meaningful differences
library(nnet)

summary(cl00_17)

cl00_17$clusters2 <- relevel(cl00_17$clusters, ref = "A")

test <- multinom(clusters2 ~ perc_poc + perc_65up + rent + emv + median_hhi + perc_new_bld + percentPOC2000 + perSixFive2000 + medHHinc2000 + MedianValue2000 + rent2000 + builtSince00_2000, data = cl00_17)

summary(test)
```



```{r}
pander(summary(lm(clusters ~ perc_poc + median_hhi + rent + perc_new_bld, data = cl_mod)))

cluster_snc <- cl00_17 %>%
  filter(!is.na(clusters)) %>%
  rename(POC2017 = perc_poc,
         POC2000 = percentPOC2000,
         EMV2000 = MedianValue2000,
         EMV2017 = emv,
         Rent2017 = rent,
         Rent2000 = rent2000,
         `65+2017` = perc_65up,
         `65+2000` = perSixFive2000,
         HHI2000 = medHHinc2000,
         HHI2017 = median_hhi,
         `New Builds2017` = perc_new_bld,
         `New Builds2000` = builtSince00_2000) %>%
  gather(2:13, key = "Variable_year", value = "Value") %>%
  separate(Variable_year, into = c("Variable", "Year"), sep = -4) %>%
  mutate(tract = TRACT,
         variable = Variable) %>%
  unite(Tract_var, tract, variable)

cluster_snc %>%
  filter(Variable == "65+") %>%
  ggplot(aes(Year, Value, color = clusters, group = Tract_var)) +
  scale_color_manual(values = c("#6666CC", "#FF6699", "#339999")) +
  geom_line() +
  geom_smooth(aes(group = clusters), color = "white")

write_csv(cluster_snc, "Results/Longitudinal Clustering/3-Cluster Solution Longitudinal Approach.csv")
```

# Take a look at 4 clusters

```{r}
cl00_17$clusters <- getClusters(cld_snc, 4)

# Convert clusters to numeric dummy variables
cl_mod <- cl00_17 %>%
  mutate(clusters = ifelse(clusters == "A", 1,
                           ifelse(clusters == "B", 2,
                                  ifelse(clusters == "C", 3, 4))))

```



```{r}
cluster_snc <- cl00_17 %>%
  filter(!is.na(clusters)) %>%
  rename(POC2017 = perc_poc,
         POC2000 = percentPOC2000,
         EMV2000 = MedianValue2000,
         EMV2017 = emv,
         Rent2017 = rent,
         Rent2000 = rent2000,
         `65+2017` = perc_65up,
         `65+2000` = perSixFive2000,
         HHI2000 = medHHinc2000,
         HHI2017 = median_hhi,
         `New Builds2017` = perc_new_bld,
         `New Builds2000` = builtSince00_2000) %>%
  gather(2:13, key = "Variable_year", value = "Value") %>%
  separate(Variable_year, into = c("Variable", "Year"), sep = -4) %>%
  mutate(tract = TRACT,
         variable = Variable) %>%
  unite(Tract_var, tract, variable)

#write_csv(cluster_snc, "Results/Longitudinal Clustering/4-Cluster Solution Longitudinal Approach.csv")

```

--------------------------------------------

# Longitudinal Clustering for 9 timepoints, 2000, 2010-2017, on

--------------------------------------------

## % POC
## % 65+
## % 18-
## % Bachelor's Degree
## % Limited English Proficiency (not disaggregated)
## % No-Vehicle Households
## Median Household Size
## Population (Met Council estimate)
## Total housing units (Met Council estimate)
## Median Household Income
## Reported Estimated Market Value of Home
## Median Rent
## Rent Tenure (% renters)
## % Race/Ethnicity (Disaggregated by Census categories:  Asian, Black, Hawaiian/Pacific Islander, Native American, Other Race, 2+ Races, Hispanic)
## % Households residing in a mobile home
## % in poverty (185% of federal level)
## % 25+ with Bachelor's degree
## % 25+ with Graduate/professional degree

# Evaluate correlation between EMV computed from parcel values, years 2015 and 2017, and self-reported home values in ACS

If values are "correlated enough", we can consider the self-reported values in the ACS data proxies for actual home values.  Deviance in ACS values from parcel data can also be a good thing, given that EMV in parcel data may not always be the most accurate "price point" for a home - assessors often have to make subjective judgment calls and standards vary from Assessor's office to office.

```{r}
library(tidyverse)
library(kml3d) # for longitudinal clustering
library(stringr) # for num_extract algorithm
library(MASS) # for AIC
library(GGally) # for correlation matrix
library(extrafont) # for fonts for plots
library(pander) # to tidy model output
library(openxlsx)
library(sf) # for geospatial commands
library(nngeo) # for nearest neighbor computation
library(nnet) # for neural nets in multinomial logit
library(data.table)
```

```{r}
x00_17 <- read_csv("Data/2000 and 2017 Values for SNC Tracts and Variables.csv")
x15 <- read_csv("Data/cleaned_variables2015.csv")

emv_17 <- x00_17 %>% dplyr::select(TRACT, emv) %>% mutate(TRACT = as.character(TRACT))
emv_15 <- x15 %>% dplyr::select(TRACT, MedianValue2015) %>% mutate(TRACT = as.character(TRACT))
acs_emv_17 <- acs2017 %>% dplyr::select(GEOID2, MEDHOMEVAL)
acs_emv_15 <- acs2015 %>% dplyr::select(GEOID2, MEDHOMEVAL)

emvs_17 <- left_join(emv_17, acs_emv_17, by = c("TRACT" = "GEOID2"))
emvs_15 <- left_join(emv_15, acs_emv_15, by = c("TRACT" = "GEOID2"))

emvs_17 %>%
  ggplot(aes(MEDHOMEVAL, emv)) +
  geom_point()

emvs_15 %>%
  ggplot(aes(MEDHOMEVAL, MedianValue2015)) +
  geom_point()

pander(summary(lm(MEDHOMEVAL ~ emv, data = emvs_17))) # ACS self-reported values explain 85% of variance in suburban neighborhoods
pander(summary(lm(MEDHOMEVAL ~ MedianValue2015, data = emvs_15))) # ACS self-reported values explain 80% of the variance metro-wide

```

ACS self-reported values explain ~80% of the variance metro-wide.  Excellent proxy for estimated market value.

# Import ACS data, 2010 through 2017 and process

## Calculate percentages
## Impute rent, household income, and home value where missing


```{r}
# Import data - enriched ACS created by Matt and copied to this folder from CommDev/Research/Research/Census Data/ACS/Excel Data
setwd("Data")
acs <- list.files(pattern = "acs2.*.xlsx")

list2env(purrr::map(setNames(acs, make.names(gsub("*5_tr.xlsx$", "", acs))), 
         read.xlsx), envir = .GlobalEnv)

tiger <- sf::st_read("Data/Census2010TigerTract.shp")

# Select variables, calculate percentages, impute rent, hhi, and home value where applicable

acs_df <- function(df) {
  
year <- df$YEAR %>% unique()

acs <<- df %>%
  dplyr::select(GEOID2, TCFLAG, AVGHHSIZE, WHITENH, POPTOTAL, AGEUNDER18, AGE65UP, BACHELORS, GRADPROF, POPOVER25, HH_NOVEH, HHTOTAL, LEP, LEP_SPAN, LEP_HMONG, LEP_AFRICA, MEDIANHHI, HHMOBILE, OWNEROCC, RENTEROCC, MEDHOMEVAL, MEDGRENT) %>%
  filter(TCFLAG == 1) %>% # Select metro tracts (includes core and MUSA)
  dplyr::select(-TCFLAG) %>%
  mutate(PC_POC = (POPTOTAL-WHITENH)/POPTOTAL*100,
         PC_18UNDER = AGEUNDER18/POPTOTAL*100,
         PC_65UP = AGE65UP/POPTOTAL*100,
         PC_BACHELORS = BACHELORS/POPOVER25*100,
         PC_GRADPROF = GRADPROF/POPOVER25*100,
         RENT_TENURE = RENTEROCC/(RENTEROCC + OWNEROCC)*100,
         PC_LEP = LEP/POPTOTAL*100,
         PC_LEP_SPAN = LEP_SPAN/POPTOTAL*100,
         PC_LEP_HMONG = LEP_HMONG/POPTOTAL*100,
         PC_LEP_AFRICA = LEP_AFRICA/POPTOTAL*100,
         PC_HH_MOBILE = HHMOBILE/HHTOTAL*100,
         PC_HH_NOVEH = HH_NOVEH/HHTOTAL*100) %>%
  dplyr::select(GEOID2, PC_POC, PC_18UNDER, PC_65UP, PC_BACHELORS, RENT_TENURE, PC_LEP, PC_LEP_SPAN, PC_LEP_HMONG, PC_LEP_AFRICA, PC_HH_MOBILE, PC_HH_NOVEH, MEDHOMEVAL, MEDIANHHI, MEDGRENT)

acs_tiger <- left_join(tiger, acs, by = c("GEOID10" = "GEOID2"))

missing_rent <- acs_tiger %>%
  filter(is.na(MEDGRENT))

missing_rent_tr <- missing_rent %>% dplyr::select(GEOID10)

rent_nn <- st_nn(missing_rent, acs_tiger, k = 10) # Find 10 nearest neighbors

rent_nn_df <-  data.frame(matrix(unlist(rent_nn), nrow=length(rent_nn), byrow=T))

rent_nn_tr <- bind_cols(missing_rent_tr, rent_nn_df)

rent <- rent_nn_tr %>% gather(X1:X8, key = "Neighbor_n", value = "Row")

acs_tiger_row <- acs_tiger %>%
  mutate(Row = row_number()) %>%
  as.data.frame()

rent_nbrs_tr <- left_join(rent, acs_tiger_row, by = "Row")

rent_imputed <- rent_nbrs_tr %>%
  dplyr::select(GEOID10.x, GEOID10.y, MEDGRENT) %>%
  rename(Tract = GEOID10.x,
         Neighbor = GEOID10.y) %>%
  group_by(Tract) %>%
  mutate(Av_rent = mean(MEDGRENT, na.rm = T)) %>%
  as.data.frame() %>%
  dplyr::select(Tract, Av_rent) %>%
  unique()

acs_rent_imputed <- left_join(acs, rent_imputed, by = c("GEOID2" = "Tract")) # Join back to original dataset

acs_rent <<- acs_rent_imputed %>%
  mutate(MEDGRENT = ifelse(is.na(MEDGRENT), Av_rent, MEDGRENT)) %>%
  dplyr::select(-Av_rent)

#----------------------
# Hhi imputation
#----------------------
missing_hhi <- acs_tiger %>%
  filter(is.na(MEDIANHHI))

missing_hhi_tr <- missing_hhi %>% dplyr::select(GEOID10)

hhi_nn <- st_nn(missing_hhi, acs_tiger, k = 10) # Find 10 nearest neighbors

hhi_nn_df <-  data.frame(matrix(unlist(hhi_nn), nrow=length(hhi_nn), byrow=T))

hhi_nn_tr <- bind_cols(missing_hhi_tr, hhi_nn_df)

hhi <- hhi_nn_tr %>% gather(X1:X8, key = "Neighbor_n", value = "Row")

acs_tiger_row <- acs_tiger %>%
  mutate(Row = row_number()) %>%
  as.data.frame()

hhi_nbrs_tr <- left_join(hhi, acs_tiger_row, by = "Row")

hhi_imputed <- hhi_nbrs_tr %>%
  dplyr::select(GEOID10.x, GEOID10.y, MEDIANHHI) %>%
  rename(Tract = GEOID10.x,
         Neighbor = GEOID10.y) %>%
  group_by(Tract) %>%
  mutate(Av_hhi = mean(MEDIANHHI, na.rm = T)) %>%
  as.data.frame() %>%
  dplyr::select(Tract, Av_hhi) %>%
  unique()

acs_hhi_imputed <- left_join(acs_rent, hhi_imputed, by = c("GEOID2" = "Tract")) # Join to df containing imputed rent

acs_hhi <<- acs_hhi_imputed %>%
  mutate(MEDIANHHI = ifelse(is.na(MEDIANHHI), Av_hhi, MEDIANHHI)) %>%
  dplyr::select(-Av_hhi)

#--------------------
# Home value imputation
# -------------------

missing_hv <- acs_tiger %>%
  filter(is.na(MEDHOMEVAL))

missing_hv_tr <- missing_hv %>% dplyr::select(GEOID10)

hv_nn <- st_nn(missing_hv, acs_tiger, k = 10) # Find 10 nearest neighbors

hv_nn_df <-  data.frame(matrix(unlist(hv_nn), nrow=length(hv_nn), byrow=T))

hv_nn_tr <- bind_cols(missing_hv_tr, hv_nn_df)

hv <- hv_nn_tr %>% gather(X1:X8, key = "Neighbor_n", value = "Row")

acs_tiger_row <- acs_tiger %>%
  mutate(Row = row_number()) %>%
  as.data.frame()

hv_nbrs_tr <- left_join(hv, acs_tiger_row, by = "Row")

hv_imputed <- hv_nbrs_tr %>%
  dplyr::select(GEOID10.x, GEOID10.y, MEDHOMEVAL) %>%
  rename(Tract = GEOID10.x,
         Neighbor = GEOID10.y) %>%
  group_by(Tract) %>%
  mutate(Av_hv = mean(MEDHOMEVAL, na.rm = T)) %>%
  as.data.frame() %>%
  dplyr::select(Tract, Av_hv) %>%
  unique()

acs_hv_imputed <- left_join(acs_hhi, hv_imputed, by = c("GEOID2" = "Tract")) # Join to df containing imputed rent and hhi

acs_hv <<- acs_hv_imputed %>%
  mutate(MEDHOMEVAL = ifelse(is.na(MEDHOMEVAL), Av_hv, MEDHOMEVAL)) %>%
  dplyr::select(-Av_hv)

acs_yr_tidy <<- acs_hv %>%
  gather(2:15, key = "variable", value = "value") %>%
  mutate(value = ifelse(is.na(value), 0, value)) %>%
  spread(variable, value = value)

colnames(acs_yr_tidy) <<- paste(colnames(acs_yr_tidy), year, sep = "_")

assign(paste("acs", year, sep = "_"), acs_yr_tidy, envir = .GlobalEnv)

}

df_list <- list(acs2010, acs2011, acs2012, acs2013, acs2014, acs2015, acs2016, acs2017)

map(df_list, acs_df)

acs_1011 <- full_join(acs_2010, acs_2011, by = c("GEOID2_2010" = "GEOID2_2011"))
acs_1012 <- full_join(acs_1011, acs_2012, by = c("GEOID2_2010" = "GEOID2_2012"))
acs_1013 <- full_join(acs_1012, acs_2013, by = c("GEOID2_2010" = "GEOID2_2013"))
acs_1014 <- full_join(acs_1013, acs_2014, by = c("GEOID2_2010" = "GEOID2_2014"))
acs_1015 <- full_join(acs_1014, acs_2015, by = c("GEOID2_2010" = "GEOID2_2015"))
acs_1016 <- full_join(acs_1015, acs_2016, by = c("GEOID2_2010" = "GEOID2_2016"))
acs_full <- full_join(acs_1016, acs_2017, by = c("GEOID2_2010" = "GEOID2_2017"))

acs_full_t <- acs_full %>%
  rename(AA_Tract = GEOID2_2010) %>%
  dplyr::select(-PC_LEP_AFRICA_2016, -PC_LEP_AFRICA_2017, -PC_LEP_HMONG_2016, -PC_LEP_HMONG_2017)

acs_cluster <- acs_full_t %>%
  dplyr::select(noquote(order(colnames(acs_full_t)))) %>%
  rename(Tract = AA_Tract)

#fwrite(acs_cluster, "Data/14-Var 2010-2017 ACS Clustering Dataset.csv")

```

# Correct denominator for % with bachelor's, extract new variables & timepoints desired for addition to clustering

```{r}
library(openxlsx)
library(tidyverse)
library(data.table)
setwd("Data")
acs <- list.files(pattern = "acs2.*.xlsx")

list2env(purrr::map(setNames(acs, make.names(gsub("*5_tr.xlsx$", "", acs))), 
         read.xlsx), envir = .GlobalEnv)

# Select added variables (% poverty, % with a bachelor's degree, % with a professional degree)
new_vars_df <- function(df) {
  
year <- df$YEAR %>% unique()

acs <<- df %>%
  dplyr::select(GEOID2, TCFLAG, BACHELORS, GRADPROF, POPOVER25, POV185RATE, WHITENH, BLACKNH, AMINDNH, ASIANNH, PACIFICNH, OTHERNH, MULTRACENH, POPTOTAL, HISPPOP) %>%
  filter(TCFLAG == 1) %>% # Select metro tracts (includes core and MUSA)
  dplyr::select(-TCFLAG) %>%
  mutate(PC_BACHELORS = BACHELORS/POPOVER25*100,
         PC_GRADPROF = GRADPROF/POPOVER25*100,
         PC_POV185 = POV185RATE*100,
         PC_WHITE = WHITENH/POPTOTAL*100,
         PC_BLACK = BLACKNH/POPTOTAL*100,
         PC_NATIVE = AMINDNH/POPTOTAL*100,
         PC_ASIAN = ASIANNH/POPTOTAL*100,
         PC_HAWAIIANPCFIS = PACIFICNH/POPTOTAL*100, 
         PC_OTHERRACE = OTHERNH/POPTOTAL*100,
         PC_TWORACE = MULTRACENH/POPTOTAL*100,
         PC_HISPPOP = HISPPOP/POPTOTAL*100) %>%
  dplyr::select(GEOID2, PC_BACHELORS, PC_GRADPROF, PC_POV185, PC_WHITE, PC_BLACK, PC_NATIVE, PC_OTHERRACE, PC_TWORACE, PC_ASIAN, PC_HAWAIIANPCFIS, PC_HISPPOP)

acs_yr_tidy <<- acs %>%
  gather(2:3, key = "variable", value = "value") %>%
  mutate(value = ifelse(is.na(value), 0, value)) %>%
  spread(variable, value = value)

colnames(acs_yr_tidy) <<- paste(colnames(acs_yr_tidy), year, sep = "_")

assign(paste("acs", year, sep = "_"), acs_yr_tidy, envir = .GlobalEnv)
}

df_list <- list(acs2010, acs2011, acs2012, acs2013, acs2014, acs2015, acs2016, acs2017)

map(df_list, new_vars_df)

acs_1011 <- full_join(acs_2010, acs_2011, by = c("GEOID2_2010" = "GEOID2_2011"))
acs_1012 <- full_join(acs_1011, acs_2012, by = c("GEOID2_2010" = "GEOID2_2012"))
acs_1013 <- full_join(acs_1012, acs_2013, by = c("GEOID2_2010" = "GEOID2_2013"))
acs_1014 <- full_join(acs_1013, acs_2014, by = c("GEOID2_2010" = "GEOID2_2014"))
acs_1015 <- full_join(acs_1014, acs_2015, by = c("GEOID2_2010" = "GEOID2_2015"))
acs_1016 <- full_join(acs_1015, acs_2016, by = c("GEOID2_2010" = "GEOID2_2016"))
acs_full <- full_join(acs_1016, acs_2017, by = c("GEOID2_2010" = "GEOID2_2017")) %>% rename(Tract = GEOID2_2010) 

acs_14_vars <- fread("Data/14-Var 2010-2017 ACS Clustering Dataset.csv")
acs_14_tidy <- acs_14_vars %>%
  gather(2:110, key = "var_name", value = "var_value") %>%
  separate(var_name, into = c("var", "var_year"), sep = -4) %>%
  filter(var != "PC_BACHELORS_") %>%
  unite(var_name, var, var_year, sep = "") %>%
  spread(var_name, value = var_value) %>%
  mutate(Tract = as.character(Tract))

acs_17_vars <- left_join(acs_14_tidy, acs_full, by = c("Tract"))

# Get Matt's estimates of population and housing units
sa <- read.xlsx("Data/estimates_V2018_tract.xlsx") 

sa_pop <- sa %>%
  filter(EST_YEAR != 2018) %>%
  dplyr::select(TR10, EST_YEAR, POPTOTAL_EST) %>%
  rename(Tract = TR10) %>%
  mutate(POP_NAME = "POPTOTAL_EST") %>%
  unite(POP_YR, POP_NAME, EST_YEAR) %>%
  spread(POP_YR, value = POPTOTAL_EST)

sa_hu <- sa %>%
  filter(EST_YEAR != 2018) %>%
  dplyr::select(TR10, EST_YEAR, HUTOTAL_EST) %>%
  rename(Tract = TR10) %>%
  mutate(HU_NAME = "HUTOTAL_EST") %>%
  unite(HU_YR, HU_NAME, EST_YEAR) %>%
  spread(HU_YR, value = HUTOTAL_EST)

sa_pop10 <- sa %>%
  dplyr::select(TR10, POPTOTAL10) %>%
  unique() %>%
  rename(POPTOTAL_EST_2010 = POPTOTAL10,
         Tract = TR10)

sa_hu10 <- sa %>%
  dplyr::select(TR10, HUTOTAL10) %>%
  unique() %>%
  rename(HUTOTAL_EST_2010 = HUTOTAL10,
         Tract = TR10)

# Read in variables for 2000 block groups - tract = first 11 digits of the block group ID
options(scipen =999)
census_00 <- read_csv("Data/CEN2000_2010boundaries2.csv")

census_00_rename <- census_00 %>%
  rename(MEDHOMEVAL = HHMEDVAL,
         MEDGRENT = GROSSRENT,
         MEDIANHHI = HHMEDINC)

census_00_tr <- census_00_rename %>%
  dplyr::select(noquote(order(colnames(census_00_rename)))) %>%
  gather(11:26, key = "Pc_cat", value = "Value_pc") %>%
  mutate(Value_gross = ifelse(Pc_cat == "PC_BACHELORS" | Pc_cat == "PC_GRADPROF", Value_pc * POPOVER25, Value_pc * TOTALPOP),
         Renters = RENT_TENURE * OCC_HOUSING) %>%
  dplyr::select(-Value_pc) %>%
  spread(Pc_cat, value = Value_gross) %>%
  mutate(AA_TR10 = substring(GEOID10, 1, 11)) %>%
  dplyr::select(-AVGHHSIZE, -MEDGRENT, -MEDHOMEVAL, -MEDIANHHI, -RENT_TENURE) # remove categories that aren't summed

# 2000 variables to be summed - summed
tracts_00_sum <- census_00_tr %>%
  dplyr::select(noquote(order(colnames(census_00_tr)))) %>%
  dplyr::select(-GEOID10) %>%
  gather(2:25, key = "Category", value = "Value") %>%
  group_by(AA_TR10, Category) %>%
  mutate(Value_summed = sum(Value, na.rm = T)) %>%
  ungroup() %>%
  dplyr::select(-Value) %>%
  unique() %>%
  spread(Category, value = Value_summed) %>%
  dplyr::select(AA_TR10, OCC_HOUSING, TOTALPOP, POPOVER25, HOUSEHOLDS, everything()) %>%
  gather(6:25, key = "Category", value = "Value") %>%
  mutate(Category_prefix = substring(Category, 1, 2)) %>%
  mutate(Percentage_value = ifelse(Category_prefix == "PC" & Category != "PC_BACHELORS" & Category != "PC_GRADPROF", Value/TOTALPOP * 100,
                                   ifelse(Category == "HISPOP", Value/TOTALPOP * 100,
                                          ifelse(Category == "PC_BACHELORS" | Category == "PC_GRADPROF", Value/POPOVER25 *100,
                                                 ifelse(Category == "Renters", Value/OCC_HOUSING * 100,
                                                        ifelse(Category == "HHMOBILE", Value/HOUSEHOLDS *100, Value)))))) %>%
  dplyr::select(AA_TR10, Percentage_value, TOTALPOP, Category) %>%
  rename(TR10 = AA_TR10) %>%
  mutate(Year = 2000) %>%
  unite(Category_yr, Category, Year) %>%
  spread(Category_yr, value = Percentage_value) %>%
  rename(Tract = TR10,
         POPTOTAL_EST_2000 = TOTALPOP,
         HUTOTAL_EST_2000 = HOUSING_UNITS_2000,
         RENT_TENURE_2000 = Renters_2000,
         PC_HISPPOP_2000 = HISPOP_2000,
         PC_HH_NOVEH_2000 = PC_HHNOVEH_2000,
         PC_LEP_SPAN_2000 = PC_LEPSPAN_2000,
         PC_HH_MOBILE_2000 = HHMOBILE_2000)

# 2000 medians and averages - from Dennis' dataset
med_av_00 <- read_csv("Data/cleaned_variables2000.csv")

# Select median gross rent, median EMV and median HHI from 2000 dataset
rent_emv_hhi_00 <- med_av_00 %>%
  dplyr::select(medHHinc2000, MedianValue2000, rent2000, TRACT) %>%
  rename(MEDGRENT_2000 = rent2000,
         MEDHOMEVAL_2000 = MedianValue2000,
         MEDIANHHI_2000 = medHHinc2000,
         Tract = TRACT) %>%
  mutate(Tract = as.character(Tract))
  

acs_sa_pop <- left_join(acs_17_vars, sa_pop, by = c("Tract")) # Add SAE pops 2011-2017
acs_sa_pop2 <- left_join(acs_sa_pop, sa_pop10, by = c("Tract")) # Add census pop (2010)
acs_sa_hu <- left_join(acs_sa_pop2, sa_hu, by = c("Tract")) # Add SAE HUs 2011-2017
acs_sa <- left_join(acs_sa_hu, sa_hu10, by = c("Tract")) # Add census HUs (2010)
acs_sum_vars <- left_join(acs_sa, tracts_00_sum, by = c("Tract")) # Add all 2000 data except medians and averages
acs_all_vars <- left_join(acs_sum_vars, rent_emv_hhi_00, by = c("Tract" = "Tract")) %>% # Add medians and averages for 2000 data
  rename(AA_TRACT = Tract) %>% # rename tract so it's first in columns
  unique() %>% # For some reason, four tracts get joined twice, but have same values for all variables...? Remove duplicates
  dplyr::select(-clusters) # remove previously created clusters

cluster_num <- acs_all_vars %>%
  gather(2:229, key = "var_name", value = "var_value") %>%
  mutate(var_value = as.numeric(var_value)) %>%
  spread(var_name, value = var_value)

cluster_data <- cluster_num %>%
  dplyr::select(noquote(order(colnames(cluster_num)))) %>%
  rename(Tract = AA_TRACT)

cluster_data_names <- cluster_data %>%
  gather(key = "Variable_name", value = "var_value") %>%
  dplyr::select(Variable_name) %>%
  unique() %>%
  mutate(ID = row_number()) %>%
  filter(Variable_name != "Tract") %>%
  separate(Variable_name, into = c("Variable", "Year"), sep = -4) %>%
  mutate(Year = as.numeric(Year)) %>%
  group_by(Variable) %>%
  mutate(Year_min = min(Year),
         Year_max = max(Year)) %>%
  ungroup() %>%
  filter(Year == Year_min | Year == Year_max)

write_csv(cluster_data, "Data/25-Variable 2000, 2010-2017 Clustering Dataset.csv")

```

# Longitudinal Clustering - 25 Variables, 2000, 2010-2017

```{r}
#cluster_data <- read_csv("Data/25-Variable 2000, 2010-2017 Clustering Dataset.csv")

cld_snc <- cld3d(cluster_data, timeInData = list(hu = 2:10, rent = 11:19, homeval = 20:28, hhi = 29:37, yt18 = 38:46, ot65 = 47:55, asian = 56:64, bachelors = 65:73, black = 74:82, gradprof = 83:91, pacific = 92:100, mobile = 101:109, noveh = 110:118, hisp = 119:127, lep = 128:136, lepaf = 137:142, lephmong = 143:148, lepspan = 149:157, native = 158:166, otherrace = 167:175, poc = 176:184, pov185 = 185:193, tworace = 194:202, pop = 212:220, rent = 221:229))

set.seed(410)
kml3d(cld_snc, nbClusters = 8) # Any number of clusters exceeding 6 must be specified using nbClusters
#choice(cld_snc)

# Take a look at 8 clusters
set.seed(410)
cluster_data$clusters <- getClusters(cld_snc, 8)

cluster_snc <- cluster_data %>%
  filter(!is.na(clusters)) %>%
  dplyr::select(Tract, clusters, everything()) %>%
  gather(3:230, key = "Variable_year", value = "Value") %>%
  mutate(Value = as.numeric(Value)) %>%
  separate(Variable_year, into = c("Variable", "Year"), sep = -4) %>%
  separate(Variable, into = c("Variable", "underscore"), sep = -1) %>%
  dplyr::select(-underscore)

write_csv(cluster_snc, "Results/Longitudinal Clustering/8-Clusters, All Timepoints, 25-Variables.csv")
```

# Longitudinal Clustering - 25 Variables; 2000, 2010, and 2017

```{r}
cluster_full <- read_csv("Data/25-Variable 2000, 2010-2017 Clustering Dataset.csv")

cluster_3 <- cluster_full %>%
  gather(2:230, key = "Variable", value = "Value") %>%
  separate(Variable, into = c("Variable", "Year"), sep = -4) %>%
  mutate(LEP_hmong_af = ifelse(Variable == "PC_LEP_HMONG_" | Variable == "PC_LEP_AFRICA_", 1, 0),
         LEP_end_yr = ifelse(Year == 2015 & LEP_hmong_af == 1, 1, 0)) %>%
  filter(Year == 2000 | Year == 2010 | Year == 2017 | LEP_end_yr == 1) %>%
  filter(Variable != "PC_WHITE_") %>%
  unite(Variable_yr, Variable, Year, sep = "") %>%
  mutate(Value = as.numeric(Value)) %>%
  dplyr::select(-LEP_hmong_af, -LEP_end_yr) %>%
  spread(Variable_yr, value = Value) %>%
  as.data.frame()

names(cluster_3)

#write_csv("Data/25-Variable 2000, 2010, 2017 Clustering Dataset.csv")
```


```{r}
#cluster_3 <- read_csv("Data/25-Variable 2000, 2010, 2017 Clustering Dataset.csv")

cld_snc_3 <- cld3d(cluster_3, timeInData = list(hu = 2:4, rent = 5:7, homeval = 8:10, hhi = 11:13, yt18 = 14:16, ot65 = 17:19, asian = 20:22, bachelors = 23:25, black = 26:28, gradprof = 29:31, pacific = 32:34, mobile = 35:37, noveh = 38:40, hisp = 41:43, lep = 44:46, lepaf = 47:48, lephmong = 49:50, lepspan = 51:53, native = 54:56, otherrace = 57:59, poc = 60:62, pov185 = 63:65, tworace = 66:68, pop = 69:71, rent = 72:74))

set.seed(410)
kml3d(cld_snc_3, nbClusters = 8) # Any number of clusters exceeding 6 must be specified using nbClusters
#choice(cld_snc)

# Take a look at 8 clusters
set.seed(410)
cluster_3$clusters <- getClusters(cld_snc_3, 8)

cluster_3_snc <- cluster_3 %>%
  filter(!is.na(clusters)) %>%
  dplyr::select(Tract, clusters, everything()) %>%
  gather(3:75, key = "Variable_year", value = "Value") %>%
  mutate(Value = as.numeric(Value)) %>%
  separate(Variable_year, into = c("Variable", "Year"), sep = -4) %>%
  separate(Variable, into = c("Variable", "underscore"), sep = -1) %>%
  dplyr::select(-underscore)

write_csv(cluster_3_snc, "Results/Longitudinal Clustering/8-Clusters, 3 Timepoints, 25-Variables.csv")

```

